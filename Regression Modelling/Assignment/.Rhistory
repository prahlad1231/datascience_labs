library("plot3D")
library(dplyr)
library(threejs)
library(rgl)
library(magick)
movie3d(movie = "3DAnimatedScatterPlot",
spin3d(axis = c(0,0,1), rpm = 7),
duration = 5,
dir = getwd(),
type = "gif",
clean = TRUE)
#### plots using plotly
install.packages("plotly")
library(plotly)
# load iris dataset
data("iris")
# create vectors for plots
x <- iris$Sepal.Length
y <- iris$Petal.Length
z <- iris$Sepal.Width
############## QUESTION 4 #############
# scatter plot
plot_ly(iris, x=~x, y=~y, z=~z)
# you can also pass the names of the variables
plot_ly(iris,
x=~Sepal.Length,
y=~Sepal.Width,
z=~Petal.Length)
# add colour
plot_ly(iris, x=~x, y=~y, z=~z, color = ~Species)
p <- plot_ly(iris, x=~x, y=~y, z=~z)
p <- add_markers(p, color = ~Species)
p
# or use pipes
p <- plot_ly(iris, x=~x, y=~y, z=~z) %>%
add_markers(p, color = ~Species)
p
# or use pipes
p <- plot_ly(iris, x=~x, y=~y, z=~z) %>%
add_markers(p, color = ~Species)
p
# add labels to the plot
variables <-names(iris)
layout(p, scene = list(xaxis = list(title = variables[1]),
yaxis = list(title = variables[2]),
zaxis = list(title = variables[3])))
rm(list= ls())
# load iris dataset
data("iris")
head(iris)
# create vectors for plots
x <- iris$Sepal.Length
y <- iris$Petal.Length
z <- iris$Sepal.Width
library("plot3D")
###################### Exercise 1: 3-D plots #######################
scatter3D(x, y, z, clab = c("Sepal", "Width (cm)"))
###################### Exercise 1: 3-D plots #######################
scatter3D(x, y, z, clab = c("Sepal", "Width (cm)"))
# remove color bar
scatter3D(x, y, z, colkey = F)
capabilities("tcltk")
# change the style
# colvar: color of the points
# col: color the points
# pch: point shape
# cex: size of the points
scatter3D(x,y,z, colvar = NULL, col = "blue", pch=19, cex=0.9)
# full box
scatter3D(x,y,z, bty = "f", colkey = F, main="bty=f")
# grey background with white grid lines and tick numbers
scatter3D(x,y,z, bty="g", colkey = F, main="bty=g", ticktype="detailed")
# full box
scatter3D(x,y,z, bty = "f", colkey = F, main="bty=f")
# grey background with white grid lines and tick numbers
scatter3D(x,y,z, bty="g", colkey = F, main="bty=g", ticktype="detailed")
# User defined
scatter3D(x,y,z, pch=18, bty="u", colkey=F, main="bty=u", col.panel="royalblue", expand=0.4, col.grid="linen")
library(dplyr)
library(threejs)
############### EXERCISE 2 ###########
scatterplot3js(x,y,z, color = rainbow(length(z)))
library(shiny)
ui <- fluidPage(
numericInput(inputId = "n", "Sample size", value=25),
plotOutput(outputId = "hist")
)
server <- function(input, output) {
output$hist <- renderPlot({
hist(rnorm(input$n))
})
}
# RUNNING APP
shinyApp(ui = ui, server = server)
# Exercise 5
library(shiny)
library(rgl)
#library(plot3D)
library(car)
data("iris")
data("iris")
# creating vectors for plots
x <- iris$Sepal.Length
y <- iris$Petal.Length
z <- iris$Sepal.Width
ui <- fluidPage(
rglwidgetOutput("plot", width = 800, height = 600)
)
server <- function(input, output) {
output$plot <- renderRglwidget({
open3d(useNULL = T)
scatter3D(x,y,z,groups=iris$Species,
col= as.numeric(iris$Species), surface=F)
rglwidget()
})
}
# RUNNING APP
shinyApp(ui = ui, server = server)
server <- function(input, output) {
output$plot <- renderRglwidget({
open3d(useNULL = T)
scatter3d(x,y,z,groups=iris$Species,
col= as.numeric(iris$Species), surface=F)
rglwidget()
})
}
# RUNNING APP
shinyApp(ui = ui, server = server)
library(shiny)
set.seed(100)
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/Exercise6')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/Exercise7')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/Exercise7')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/Exercise6')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/take_home')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/take_home')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/take_home')
colnames(iris)
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/take_home')
runApp('Documents/UC/Semester 3/Labs/AR_VR/week3/Exercise7')
# Load the dataset
data(trees)
# Calculate average and variance of Volume
average_volume <- mean(trees$Volume, na.rm = TRUE)
variance_volume <- var(trees$Volume, na.rm = TRUE)
# Print the results
cat("Average =", round(average_volume, 2), "and Variance =", round(variance_volume, 2))
cor(trees$Girth, trees$Height)
cor(trees$Height, trees$Girth)
lm(trees$Height ~ trees$Girth)
model <- lm(trees$Height ~ trees$Girth)
summary(model)
?lm()
model <- lm(trees$Girth ~ trees$Height)
summary(model)
round(-6.18839, 2)
# Fit a linear regression model
linear_model <- lm(Girth ~ Height, data = trees)
# Calculate intercept, slope, R-squared
intercept <- coef(linear_model)[1]
slope <- coef(linear_model)[2]
r_squared <- summary(linear_model)$r.squared
# Predict the value for the last tree
last_tree <- tail(trees, n = 1)
predicted_value <- predict(linear_model, newdata = last_tree)
residual <- last_tree$Girth - predicted_value
# Print the results
cat("Intercept estimate:", round(intercept, 2), "\n")
cat("Slope estimate:", round(slope, 2), "\n")
cat("R-squared value:", round(r_squared, 2), "\n")
cat("Predicted value for the last tree:", round(predicted_value, 2), "\n")
cat("Residual for the last tree:", round(residual, 2))
head(trees, n=1)
first_tree <- head(trees, n=1)
pv <- predict(linear_model, newdata = last_tree)
pv
model <- lm(trees$Girth ~ trees$Height)
predict(model)
head(trees, n=1)
tail(trees, n=1)
20.6-16.061605
# install devtools, not needed if already installed
install.packages("devtools")
# install aframer and arframer
devtools::install_github("JohnCoene/aframer") # select option 3 (none)
# load libraries
library(aframer)
library(arframer)
devtools::install_github("JohnCoene/arframer") # select option 3 (none)
# load libraries
library(aframer)
library(arframer)
# it creates the scenes in html code
embed_aframe(
a_scene(
a_dependency(),
a_box(position = "-1 0.5 -3", rotation = "0 45 0", color = "#4CC3D9"),
a_sphere(position = "0 1.25 -5", radius = "1.25", color = "#EF2D5E"),
a_cylinder(position = "1 0.75 -3", radius = "0.5", height = "1.5", color = "#FFC65D"),
a_plane(position = "0 0 -4", rotation = "-90 0 0", width = "4", height = "4", color = "#7BC8A4"),
a_sky(color="#ECECEC")
)
)
# it runs the scene in web browser
browse_aframe(
a_scene(
a_dependency(),
a_box(position = "-1 0.5 -3", rotation = "0 45 0", color = "#4CC3D9"),
a_sphere(position = "0 1.25 -5", radius = "1.25", color = "#EF2D5E"),
a_cylinder(position = "1 0.75 -3", radius = "0.5", height = "1.5", color = "#FFC65D"),
a_plane(position = "0 0 -4", rotation = "-90 0 0", width = "4", height = "4", color = "#7BC8A4"),
a_sky(color="#ECECEC")
)
)
data("swiss")
str(swiss)
correlation <- cor(swiss$Fertility, swiss$Agriculture)
cat("Correlation coefficient between Fertility and Agriculture:", round(correlation, 3))
# Get the coefficients of the model
intercept <- round(coef(lm_model)[1], 3)
source("~/.active-rstudio-document")
summary(lm_model)
standardized_residual
# Calculate the standardized residual for province #37
standardized_residual <- round(rstandard(lm_model)[37], 3)
standardized_residual
resid(lm_model)[37]
std_err
# Calculate the standard error for regression
std_error <- round(summary(lm_model)$sigma, 3)
std_err
std_error
# Load the swiss dataset
data(swiss)
# Fit a linear model
lm_model <- lm(Fertility ~ Agriculture + Education + Infant.Mortality, data = swiss)
# Get the coefficients of the model
intercept <- round(coef(lm_model)[1], 2)
agriculture_coeff <- round(coef(lm_model)[2], 2)
education_coeff <- round(coef(lm_model)[3], 2)
infant_mortality_coeff <- round(coef(lm_model)[4], 2)
# Calculate the adjusted R-squared
adjusted_r_squared <- round(summary(lm_model)$adj.r.squared, 2)
# Define the values for prediction
agriculture_value <- 36.7
education_value <- 8
infant_mortality_value <- 25.6
# Predict Fertility for the given values
predicted_value <- predict(lm_model, newdata = data.frame(Agriculture = agriculture_value, Education = education_value, Infant.Mortality = infant_mortality_value))
# Calculate the 90% prediction interval
prediction_interval <- predict(lm_model, newdata = data.frame(Agriculture = agriculture_value, Education = education_value, Infant.Mortality = infant_mortality_value), interval = "prediction")
# Calculate the F-statistic and p-value for the nested F-test
anova_result <- anova(lm_model)
f_value <- round(anova_result$`F value`[2], 2)
p_value <- format(pchisq(anova_result$`F value`[2], df1 = 2, df2 = nrow(swiss) - length(coef(lm_model))), scientific = TRUE, digits = 2)
source("~/.active-rstudio-document")
# Load the swiss dataset
data(swiss)
# Fit a linear model
lm_model <- lm(Fertility ~ Agriculture + Education + Infant.Mortality, data = swiss)
# Print the coefficients of the model
coefficients(lm_model)
# Print the coefficients of the model
coefficients(lm_model)
coefficients <- coef(lm_model)
# Round the coefficients to two decimal places
coefficients <- round(coefficients, 2)
# Extract the individual coefficients
intercept <- coefficients[1]
agriculture_coeff <- coefficients[2]
education_coeff <- coefficients[3]
infant_mortality_coeff <- coefficients[4]
# Print the fitted equation
cat("The fitted equation of the regression is:\n")
cat("Predicted_Fertility =", intercept, "+", agriculture_coeff, "Agriculture +", education_coeff, "Education +", infant_mortality_coeff, "Infant.Mortality\n")
# Calculate the adjusted R-squared value
adjusted_r_squared <- summary(lm_model)$adj.r.squared
# Define the values for prediction
new_data <- data.frame(
Agriculture = 36.7,
Education = 8,
Infant.Mortality = 25.6
)
# Calculate the 90% prediction interval
prediction_interval <- predict(lm_model, newdata = new_data, interval = "prediction", level = 0.90)
# Extract the lower and upper bounds of the prediction interval
lower_bound <- prediction_interval[1]
upper_bound <- prediction_interval[2]
# Print the adjusted R-squared and the prediction interval
cat("The adjusted R-squared value of the regression is:", round(adjusted_r_squared, 2), "\n")
cat("A 90% prediction interval for a province with Agriculture = 36.7, Education = 8, and Infant.Mortality = 25.6 is (", round(lower_bound, 2), ",", round(upper_bound, 2), ")\n")
# Calculate the adjusted R-squared value
adjusted_r_squared <- summary(lm_model)$adj.r.squared
# Define the values for prediction
new_data <- data.frame(
Agriculture = 36.7,
Education = 8,
Infant.Mortality = 25.6
)
# Calculate the 90% prediction interval
prediction_interval <- predict(lm_model, newdata = new_data, interval = "prediction", level = 0.90)
# Extract the lower and upper bounds of the prediction interval
lower_bound <- prediction_interval[1]
upper_bound <- prediction_interval[2]
# Print the adjusted R-squared and the prediction interval
cat("The adjusted R-squared value of the regression is:", round(adjusted_r_squared, 2), "\n")
cat("A 90% prediction interval for a province with Agriculture = 36.7, Education = 8, and Infant.Mortality = 25.6 is (", round(lower_bound, 2), ",", round(upper_bound, 2), ")\n")
# Calculate the adjusted R-squared value
adjusted_r_squared <- summary(lm_model)$adj.r.squared
# Define the values for prediction
new_data <- data.frame(
Agriculture = 36.7,
Education = 8,
Infant.Mortality = 25.6
)
# Calculate the 90% prediction interval
prediction_interval <- predict(lm_model, newdata = new_data, interval = "prediction", level = 0.90)
# Extract the lower and upper bounds of the prediction interval
lower_bound <- prediction_interval[1]
upper_bound <- prediction_interval[2]
# Print the adjusted R-squared and the prediction interval
cat("The adjusted R-squared value of the regression is:", round(adjusted_r_squared, 2), "\n")
cat("A 90% prediction interval for a province with Agriculture = 36.7, Education = 8, and Infant.Mortality = 25.6 is (", round(lower_bound, 2), ",", round(upper_bound, 2), ")\n")
Finally, use a nested F-test to test if Agriculture and Education are jointly significant. Its F value is
and p value is
full_model <- lm(Fertility ~ Agriculture + Education + Infant.Mortality, data = swiss)
# Fit a reduced model without Agriculture and Education
reduced_model <- lm(Fertility ~ Infant.Mortality, data = swiss)
# Perform the nested F-test
nested_f_test <- anova(reduced_model, full_model)
# Extract the F value and p value
f_value <- nested_f_test$`F value`[2]
p_value <- nested_f_test$`Pr(>F)`[2]
# Print the F value and p value
cat("The nested F-test F value is:", round(f_value, 2), "and p value is", format(p_value, scientific = TRUE, digits = 2), "\n")
full_model <- lm(Fertility ~ Agriculture + Education + Infant.Mortality, data = swiss)
# Fit a reduced model without Agriculture and Education
reduced_model <- lm(Fertility ~ Infant.Mortality, data = swiss)
# Perform the nested F-test
nested_f_test <- anova(reduced_model, full_model)
# Extract the F value and p value
f_value <- nested_f_test$`F value`[2]
p_value <- nested_f_test$`Pr(>F)`[2]
# Print the F value and p value
cat("The nested F-test F value is:", round(f_value, 2), "and p value is", format(p_value, scientific = TRUE, digits = 2), "\n")
# Determine whether to reject the null hypothesis
alpha <- 0.05  # significance level
if (p_value < alpha) {
cat("We reject H0: beta_Agriculture = beta_Education = 0\n")
cat("We conclude that Agriculture and Education are jointly significant.\n")
} else {
cat("We do not reject H0: beta_Agriculture = beta_Education = 0\n")
cat("There is not enough evidence to conclude that Agriculture and Education are jointly significant.\n")
}
# Print the F value and p value
cat("The nested F-test F value is:", round(f_value, 2), "and p value is", format(p_value, scientific = TRUE, digits = 2), "\n")
# Extract the F value and p value
f_value <- nested_f_test$`F value`[2]
p_value <- nested_f_test$`Pr(>F)`[2]
# Print the F value and p value
cat("The nested F-test F value is:", round(f_value, 2), "and p value is", format(p_value, scientific = TRUE, digits = 2), "\n")
f_value
p_value
prediction_interval
lower_bound
upper_bound
# Extract the lower and upper bounds of the prediction interval
lower_bound <- prediction_interval[2]
lower_bound
upper_bound <- prediction_interval[3]
upper_bound
round(lower_bound, 2)
round(upper_bound, 2)
setwd("/Users/prahladpanthi/Documents/UC/Semester 3/Labs/Regression Modelling/Assignment")
setwd("/Users/prahladpanthi/Documents/UC/Semester 3/Labs/Regression Modelling/Assignment")
setwd("/Users/prahladpanthi/Documents/UC/Semester 3/Labs/Regression Modelling/Assignment")
install.packages(islr)
install.packages(islr)
install.packages("islr")
install.packages("ISLR")
hitters = ISLR::Hitters
summary(hitters)
colnames(hitters)
install.packages("DataExplorer")
library(DataExplorer)
DataExplorer::create_report(hitters)
is.na(hitters)
sum(is.na(hitters))
# remove all missing values
hitters = na.omit(hitters)
sum(is.na(hitters))
library(ggplot2)
# Create a histogram for the "Salary" variable
hist_plot <- ggplot(hitters, aes(x = Salary)) +
geom_histogram(fill = "lightblue", color = "black", bins = 20) +
labs(title = "Salary Histogram", x = "Salary", y = "Frequency")
hist_plot
# Create a boxplot for the "Salary" variable
box_plot <- ggplot(Hitters, aes(y = Salary)) +
geom_boxplot(fill = "lightgreen", color = "black") +
labs(title = "Salary Boxplot", y = "Salary")
box_plot
# Create a boxplot for the "Salary" variable
box_plot <- ggplot(Hitters, aes(y = Salary)) +
geom_boxplot(fill = "lightgreen", color = "black") +
labs(title = "Salary Boxplot", y = "Salary")
# Create a boxplot for the "Salary" variable
box_plot <- ggplot(hitters, aes(y = Salary)) +
geom_boxplot(fill = "lightgreen", color = "black") +
labs(title = "Salary Boxplot", y = "Salary")
box_plot
grid.arrange(hist_plot, box_plot, ncol=2)
library(tidyverse)
grid.arrange(hist_plot, box_plot, ncol=2)
library(rvest)
grid.arrange(hist_plot, box_plot, ncol=2)
install.packages("caret")
library(caret)
grid.arrange(hist_plot, box_plot, ncol=2)
library(grid)
grid.arrange(hist_plot, box_plot, ncol=2)
library(gridExtra)
grid.arrange(hist_plot, box_plot, ncol=2)
# Create a histogram for the "Salary" variable
hist_plot <- ggplot(hitters, aes(x = Salary)) +
geom_histogram(fill = "lightblue", color = "black", bins = 100) +
labs(title = "Salary Histogram", x = "Salary", y = "Frequency")
hist_plot
grid.arrange(hist_plot, box_plot, ncol=2)
# Create a histogram for the "Salary" variable
hist_plot <- ggplot(hitters, aes(x = Salary)) +
geom_histogram(fill = "lightblue", color = "black", bins = 20) +
labs(title = "Salary Histogram", x = "Salary", y = "Frequency")
grid.arrange(hist_plot, box_plot, ncol=2)
# Create a histogram for the "Salary" variable
hist_plot <- ggplot(hitters, aes(x = Salary)) +
geom_histogram(fill = "lightblue", color = "black", bins = 20, alpha=0.7) +
labs(title = "Salary Histogram", x = "Salary", y = "Frequency")
grid.arrange(hist_plot, box_plot, ncol=2)
# Create a histogram for the "Salary" variable
hist_plot <- ggplot(hitters, aes(x = Salary)) +
geom_histogram(fill = "lightblue", color = "black", bins = 20) +
labs(title = "Salary Histogram", x = "Salary", y = "Frequency")
grid.arrange(hist_plot, box_plot, ncol=2)
# 3. Prepare inputs for glmnet (ML syntax "X, y" instead of formula y ~ x)
x = model.matrix(Salary ~ . - 1, data = hitters)  # Matrix, excluding Salary
y = hitters$Salary
install.packages("glmnet")
library(glmnet)
# 3. Prepare inputs for glmnet (ML syntax "X, y" instead of formula y ~ x)
x = model.matrix(Salary ~ . - 1, data = hitters)  # Matrix, excluding Salary
y = hitters$Salary
# 4. Fit a single model. Default: Lasso (alpha=1)
fit = glmnet(x, y, alpha = 1)  # glmnet performs multiple fits with a lambda grid
length(fit$lambda)
# Fetch a middle model, display Lambda and coefficients:
print(paste("4. Lambda =", fit$lambda[40]))
coef(fit)[, 40]
# 5. Fit various model types:
set.seed(1)
fit.ridge = glmnet(x, y, alpha = 0)   # Ridge Regression
fit.lasso = glmnet(x, y)              # Lasso
fit.elnet1 = glmnet(x, y, alpha = 0.1)  # 1st Elastic Net
fit.elnet9 = glmnet(x, y, alpha = 0.9)  # 2nd Elastic Net
# 6. Visualize the shrinking of coefficients
par(mfrow = c(2, 2))
plot(fit.ridge, xvar = "lambda", main = "Ridge (alpha=0)")
plot(fit.lasso, xvar = "lambda", main = "Lasso (alpha=1)")
plot(fit.elnet1, xvar = "lambda", main = "Elastic Net (alpha=0.1)")
plot(fit.elnet9, xvar = "lambda", main = "Elastic Net (alpha=0.9)")
# 7. Create training and test datasets
x = model.matrix(Salary ~ ., hitters)[, -1]
grid = 10^seq(10, -2, length = 100)  # Create a grid of Lambda from 0.01 to 10^10
set.seed(1)  # Generate reproducible training and test data
train = sample(1:nrow(x), nrow(x) / 2)  # Training dataset 50%
test = (-train)
y.test = y[test]
# 8. Find the optimal Lambda through Cross-Validation
set.alpha = 1  # Lasso
set.seed(1)
fit.train = glmnet(x[train, ], y[train], alpha = set.alpha, lambda = grid)  # Grid
cv.train = cv.glmnet(x[train, ], y[train], alpha = set.alpha)
par(mfrow = c(1, 1))
plot(cv.train)
bestlam.cv = cv.train$lambda.min  # Lambda with the smallest standard error
print(paste("8. Best Lambda =", bestlam.cv))
pred.test = predict(fit.train, s = bestlam.cv, newx = x[test, ])
print(paste("8. mse =", mean((pred.test - y.test)^2)))
out = glmnet(x, y, alpha = set.alpha)
# Fit with the entire dataset, grid
# Show coefficients with optimal Lambda:
predict(out, typ = "coefficients", s = bestlam.cv)[1:20,]  # [] is optional
